Caso de uso:

Tenemos un endpoint donde llega sin parar cientos de llamadas por segundo registrando un hit de un video. Cada vez que un usuario ve un vídeo se llama a ese endpoint con el id del video para poder aumentar un contador que indica el número de veces que se ha visualizado dicho vídeo.

Para no tener una sobrecarga en el sistema se realiza el siguiente flujo:

Cuando llega un hit se almacena en una cola en memoria (Deque). Tenemos un demonio que cada x segundos va a consumir todos los mensajes de esa cola, los va a agrupar por vídeo y los va a mandar a una cola de mensajería rabbitmq. La agrupación por video consiste en que si llegan 10 hits para un mismo id de video se creará un objeto VideoHit que va a tener el id del vídeo y un contador de 10 visualizaciones. Una vez que se han agrupado los hits se manda a la cola el listado de VideoHit. Como rabbitmq tiene un límite del tamaño del mensaje y podemos encontrarnos con una lista muy grande, hacemos sublistas de tamaño 50 y enviamos cada sublista por separado. Después agregamos un consumidor que podría estar en otro proyecto pero para el ejemplo lo agregamos en el mismo proyecto. Dicho consumidor consume cada mensaje que contiene una lista de 50 VideoHits y los guarda en mongodb. Para ello hace un bulk de upsert para que por cada VideoHit en caso de ya existir solo incremente su contador el número de hits que ha recibido. En caso de que no exista el registro lo crea y setea el contador con el valor que viene. Haciendo el bulk conseguimos que con una única petición a mongodb se actualicen 50 registros. El valor 50 es personalizable en función al rendimiento de la plataforma.
